{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 자연어와 단어의 분산 표현"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 단어의 의미\n",
    "우리의 말은 '문자'로 말의 의미는 '단어'로 구성, 단어의 의미를 이해 시키는 것이 이번 장에 목적\n",
    "- 시소러스를 활용한 기법\n",
    "- 통계기반 기법\n",
    "- 추론기반 기법(word2vec과 같은)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 시소러스\n",
    "시소러스란 (기본적으로는) 유의어 사전으로, '뜻이 같은 단어(동의어)'나 '뜻이 비슷한 단어(유의어)'가 한그룹으로 분류되어 있음. 또한 자연어처리에 활용되는 시소러스에서는 단어 사이의 '상위와 하위', '전체와 부분' 등 더 세세한 정의가 포함되기도 함\n",
    "\n",
    "- 가장 유명한 시소러스는 WordNet\n",
    "    - 1985년 구축을 시작, 지금까지 많은 연구와 다양한 어플리케이션에 활용\n",
    "- 시소러스에 문제점\n",
    "    - 사람이 수작업으로 레이블링하는 방식에 크나큰 결점이 존재함\n",
    "    - 시대변화에 적응이 어려움 (신조어 등)\n",
    "    - 사람을 쓰는 비용이 큼\n",
    "    - 단어의 미묘한 차이를 표현 불가 (빈티지와 레트로의 차이)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 통계기반 기법\n",
    "통계기반 기법의 목표는 사람의 지식으로 가득한 말뭉치(corpus)에서 자동으로, 그리고 효율적으로 그 핵심을 추출하는 것"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'you say goodbye and i say hello .'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"You say goodbye and I say hello.\"\n",
    "\n",
    "# 텍스트 전처리\n",
    "text = text.lower()\n",
    "text = text.replace('.', ' .')\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['you', 'say', 'goodbye', 'and', 'i', 'say', 'hello', '.']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 단어로 분할\n",
    "words = text.split(' ')\n",
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'you', 1: 'say', 2: 'goodbye', 3: 'and', 4: 'i', 5: 'hello', 6: '.'}\n",
      "{'you': 0, 'say': 1, 'goodbye': 2, 'and': 3, 'i': 4, 'hello': 5, '.': 6}\n"
     ]
    }
   ],
   "source": [
    "word2id = {}\n",
    "id2word = {}\n",
    "\n",
    "for word in words:\n",
    "    if word not in word2id:\n",
    "        new_id = len(word2id)\n",
    "        word2id[word] = new_id\n",
    "        id2word[new_id] = word\n",
    "\n",
    "print(id2word)\n",
    "print(word2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 1, 5, 6])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "corpus = [word2id[w] for w in words]\n",
    "corpus = np.array(corpus)\n",
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전처리 함수\n",
    "def preprocess(text):\n",
    "    text = text.lower()\n",
    "    text = text.replace('.', ' .')\n",
    "    words = text.split(' ')\n",
    "    \n",
    "    word2id = {}\n",
    "    id2word = {}\n",
    "    for word in words:\n",
    "        if word not in word2id:\n",
    "            new_id = len(word2id)\n",
    "            word2id[word] = new_id\n",
    "            id2word[new_id] = word\n",
    "            \n",
    "    corpus = [word2id[w] for w in words]\n",
    "    \n",
    "    return corpus, word2id, id2word\n",
    "\n",
    "text = \"You say goodbye and I say hello.\"\n",
    "corpus, word2id, id2word = preprocess(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 단어의 분산 표현\n",
    "'단어의 의미'를 정확하게 파악 할 수 있는 벡터 표현, 이를 자연어 처리에서는 분산표현이라 함"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 분포가설\n",
    "단어를 벡터로 바꾸는 연구는 수도 없이 이루어지며 그 뿌리는 '단어의 의미는 주변 단어에 의해 형성된다' 라는 것. 이를 분포가설이라 함. 이는 단어 자체에는 의미가 없고 그 단어가 사용되는 맥락이 의미를 형성한다는 것을 뜻함"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 동시발생 행렬\n",
    "어떤 단어에 주목 했을 때, 그 주변에 어떤 단어가 몇 번이나 등장하는지를 세어 집게하는 것. 이를 통계기반 기법으로 함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 동시발생 행렬 제작 함수\n",
    "def creat_co_matrix(corpus, vocab_size, window_size=1):\n",
    "    corpus_size = len(corpus)\n",
    "    co_matrix = np.zeros((vocab_size, vocab_size), dtype=np.int32)\n",
    "    \n",
    "    for idx, word_id in enumerate(corpus):\n",
    "        for i in range(1, window_size+1):\n",
    "            left_idx = idx - 1\n",
    "            right_idx = idx + 1\n",
    "            \n",
    "            if left_idx >= 0:\n",
    "                left_word_id = corpus[left_idx]\n",
    "                co_matrix[word_id, left_word_id] += 1\n",
    "                \n",
    "            if right_idx < corpus_size:\n",
    "                right_word_id = corpus[right_idx]\n",
    "                co_matrix[word_id, right_word_id] += 1\n",
    "                \n",
    "    return co_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 벡터 간 유사도\n",
    "코사인 유사도를 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cos_similarity(x, y, eps=1e-8):\n",
    "    nx = x / (np.sqrt(np.sum(x**2)) + eps)\n",
    "    ny = y / (np.sqrt(np.sum(y**2)) + eps)\n",
    "    return np.dot(nx, ny)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7071067691154799\n"
     ]
    }
   ],
   "source": [
    "text = \"You say goodbye and I say hello.\"\n",
    "corpus, word2id, id2word = preprocess(text)\n",
    "vocab_size = len(word2id)\n",
    "C = creat_co_matrix(corpus, vocab_size)\n",
    "\n",
    "c0 = C[word2id['you']]\n",
    "c1 = C[word2id['i']]\n",
    "print(cos_similarity(c0, c1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 유사 단어의 랭킹 표시\n",
    "검색어와 비슷한 단어를 유사도 순으로 출력 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/n[query] you\n",
      " goodbye: [0.99999998 0.         0.70710677 0.         0.70710677 0.70710677\n",
      " 0.        ]\n",
      " i: [0.99999998 0.         0.70710677 0.         0.70710677 0.70710677\n",
      " 0.        ]\n",
      " hello: [0.99999998 0.         0.70710677 0.         0.70710677 0.70710677\n",
      " 0.        ]\n",
      " say: [0.99999998 0.         0.70710677 0.         0.70710677 0.70710677\n",
      " 0.        ]\n",
      " and: [0.99999998 0.         0.70710677 0.         0.70710677 0.70710677\n",
      " 0.        ]\n"
     ]
    }
   ],
   "source": [
    "def most_similar(query, word2id, id2word, word_matrix, top=5):\n",
    "    # 검색어를 꺼냄\n",
    "    if query not in word2id:\n",
    "        print('%s not find' %query)\n",
    "        return\n",
    "    \n",
    "    print('/n[query] ' + query)\n",
    "    query_id = word2id[query]\n",
    "    query_vec = word_matrix[query_id]\n",
    "    \n",
    "    # 코사인 유사도 계산\n",
    "    vocab_size = len(id2word)\n",
    "    similarity = np.zeros(vocab_size)\n",
    "    for i in range(vocab_size):\n",
    "        similarity[i] = cos_similarity(word_matrix[i], query_vec)\n",
    "        \n",
    "    # 코사인 유사도를 기준으로 내림차순으로 출력\n",
    "    count = 0\n",
    "    for i in (-1*similarity).argsort():\n",
    "        if id2word[i] == query:\n",
    "            continue\n",
    "        print(' %s: %s' %(id2word[i], similarity))\n",
    "        \n",
    "        count += 1\n",
    "        if count >= top:\n",
    "            return\n",
    "        \n",
    "text = \"You say goodbye and I say hello.\"\n",
    "corpus, word2id, id2word = preprocess(text)\n",
    "vocab_size = len(word2id)\n",
    "C = creat_co_matrix(corpus, vocab_size)\n",
    "\n",
    "most_similar('you', word2id, id2word, C, top=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. 통계 기반 기법 개선하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 상호정보량\n",
    "'발생 횟수'는 좋은 특징이 아님. (ex. 'the', 'car'의 동시발생 횟수는 많지만 의미가 적음) 이러한 문제를 해결하기 위해 점별 상호정보량(PMI) 척도를 사용\n",
    "- PMI(x,y) = log2(P(x,y)/(P(x)*P(y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "동시발생 행렬\n",
      "[[0 1 0 0 0 0 0]\n",
      " [1 0 1 0 1 1 0]\n",
      " [0 1 0 1 0 0 0]\n",
      " [0 0 1 0 1 0 0]\n",
      " [0 1 0 1 0 0 0]\n",
      " [0 1 0 0 0 0 1]\n",
      " [0 0 0 0 0 1 0]]\n",
      "--------------------------------------------------\n",
      "PPMI\n",
      "[[0.    1.807 0.    0.    0.    0.    0.   ]\n",
      " [5.807 0.    4.807 0.    4.807 4.807 0.   ]\n",
      " [0.    2.807 0.    3.807 0.    0.    0.   ]\n",
      " [0.    0.    3.807 0.    3.807 0.    0.   ]\n",
      " [0.    2.807 0.    3.807 0.    0.    0.   ]\n",
      " [0.    2.807 0.    0.    0.    0.    4.807]\n",
      " [0.    0.    0.    0.    0.    2.807 0.   ]]\n"
     ]
    }
   ],
   "source": [
    "def ppmi(C, verbose=False, eps=1e-8):\n",
    "    M = np.zeros_like(C,  dtype=np.float32)\n",
    "    N = np.sum(C)\n",
    "    S = np.sum(C, axis=0)\n",
    "    total = C.shape[0] * C.shape[1]\n",
    "    cnt = 0\n",
    "    \n",
    "    for i in range(C.shape[0]):\n",
    "        for j in range(C.shape[1]):\n",
    "            pmi = np.log2(C[i, j] * N / S[j]*S[i] + eps)\n",
    "            M[i, j] = max(0, pmi)\n",
    "            \n",
    "            if verbose:\n",
    "                cnt += 1\n",
    "                if cnt % (total//100)  == 0:\n",
    "                    print('%.1f%% 완료' % (100*cnt/total))\n",
    "    return M\n",
    "\n",
    "text = \"You say goodbye and I say hello.\"\n",
    "corpus, word2id, id2word = preprocess(text)\n",
    "vocab_size = len(word2id)\n",
    "C = creat_co_matrix(corpus, vocab_size)\n",
    "W = ppmi(C)\n",
    "\n",
    "np.set_printoptions(precision=3)   ### 유효 자릿수를 세 자리로 표시\n",
    "print('동시발생 행렬')\n",
    "print(C)\n",
    "print('-'*50)\n",
    "print('PPMI')\n",
    "print(W)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 차원감소\n",
    "중요한 정보는 최대한 유지하면서 벡터의 차원을 감소시킴"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 0 0 0 0 0]\n",
      "[0.    1.807 0.    0.    0.    0.    0.   ]\n",
      "[ 0.000e+00  1.748e-01  3.821e-02  0.000e+00  0.000e+00 -9.839e-01\n",
      "  7.539e-16]\n",
      "[0.    0.175]\n"
     ]
    }
   ],
   "source": [
    "text = \"You say goodbye and I say hello.\"\n",
    "corpus, word2id, id2word = preprocess(text)\n",
    "vocab_size = len(word2id)\n",
    "C = creat_co_matrix(corpus, vocab_size)\n",
    "W = ppmi(C)\n",
    "\n",
    "# SVD\n",
    "U, S, V = np.linalg.svd(W)\n",
    "print(C[0])\n",
    "print(W[0])\n",
    "print(U[0])\n",
    "print(U[0, :2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for word, word_id in word2id.items():\n",
    "    plt.annotate(word, (U[word_id, 0], U[word_id, 1]))\n",
    "    \n",
    "plt.scatter(U[:, 0], U[:, 1], alpha=0.5)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
